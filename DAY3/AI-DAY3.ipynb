{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8715a6f-3b9d-4dd1-804b-8e7621fdd438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, the Earth is not flat.  The overwhelming scientific evidence and observations confirm that the Earth is an oblate spheroid, meaning it is slightly flattened at the poles and bulging at the equator. Here are some of the key evidence that supports the fact that the Earth is not flat:\n",
      "\n",
      "1. **Ship disappearing over the horizon**: When a ship sails away from an observer on the shore, it will eventually disappear from view as it sinks below the horizon. This is because the Earth is curved, and the observer's line of sight is gradually lowered as the ship moves further away.\n",
      "2. **Satellite imagery**: Satellite images of the Earth provide clear visual evidence of its spherical shape. Images taken by satellites in orbit around the Earth show the curvature of the planet, which would not be possible if it were flat.\n",
      "3. **Shadows on the moon**: During a lunar eclipse, the Earth passes between the sun and the moon, casting a shadow on the lunar surface. The shape of this shadow is curved, indicating that the Earth is a sphere.\n",
      "4. **Circumnavigation**: Many people have traveled around the world, completing circumnavigations of the planet. If the Earth were flat, it would be impossible to circumnavigate it without falling off the edge.\n",
      "5. **Gravity**: The force of gravity pulls objects towards the center of the Earth, which is only possible if the Earth is a sphere. On a flat Earth, gravity would not be able to act in the same way.\n",
      "6. **Measurements of the Earth's diameter**: Scientists have made precise measurements of the Earth's diameter using a variety of techniques, including satellite laser ranging and radar altimetry. These measurements confirm that the Earth is a sphere with a diameter of approximately 12,742 kilometers.\n",
      "7. **Flight routes**: Commercial airlines have flight routes that cover the entire globe, and pilots use navigation systems that assume the Earth is a sphere. If the Earth were flat, these flight routes would not be possible.\n",
      "8. **Time zones**: The Earth has 24 time zones, which are necessary because the planet is divided into 24 equal segments. This would not be possible if the Earth were flat, as there would be no need for time zones.\n",
      "9. **Eratosthenes' measurement of the Earth's circumference**: In the 3rd century BCE, the Greek mathematician Eratosthenes measured the Earth's circumference with remarkable accuracy using the angles of shadows cast by the sun at different latitudes.\n",
      "10. **Scientific consensus**: The overwhelming consensus among scientists and experts in relevant fields is that the Earth is a sphere. This consensus is based on a vast amount of evidence from various disciplines, including astronomy, geology, physics, and mathematics.\n",
      "\n",
      "In conclusion, the evidence that supports the fact that the Earth is a sphere is overwhelming and comes from a variety of fields. There is no credible evidence to support the idea that the Earth is flat.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "llm_obj = ChatGroq(model=\"llama-3.1-8b-instant\",api_key=os.getenv('GROQ_API_KEY'))\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm_obj | parser \n",
    "\n",
    "response = chain.invoke(\n",
    "    {\"input\": \"Is the Earth flat?\"}\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ee2465-8e69-486e-afa9-1b6134528b41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "690ef6a6-5eec-4479-8007-f5037e5ceecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nchain = prompt | llm | parser followed by chain.invoke({\"input\": \"Is the Earth flat?\"}).\\n\\nThe input, which is a dictionary whose key is input and value is the question, \\ngoes into prompt, of which prompt’s \\noutput goes into llm, after which llm’s output goes into parser.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "chain = prompt | llm | parser followed by chain.invoke({\"input\": \"Is the Earth flat?\"}).\n",
    "\n",
    "The input, which is a dictionary whose key is input and value is the question, \n",
    "goes into prompt, of which prompt’s \n",
    "output goes into llm, after which llm’s output goes into parser.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fd687a4-14c9-485b-8874-a46975d8e772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7e105a1-0673-4047-afe1-148d22d9ba19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"No, it's definitely round... and upside down. The poles are actually at the equator, and the equator is at the North Pole. Just think about it, when you're standing on the beach, the waves are actually flowing upwards towards the sky, but they're being held back by some invisible force that keeps them from escaping into space. It's a well-known fact that the Earth is a giant, inverted doughnut, and it's held together by a network of invisible strings.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_with_character = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a {character}. If a trickster, deliberate give the wrong answer. If a sage, give a long philosophical answer.\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "chain_with_character = prompt_with_character | llm_obj | parser\n",
    "\n",
    "response = chain_with_character.invoke(\n",
    "    {\n",
    "        \"input\": \"Is the Earth flat?\",\n",
    "        \"character\": \"trickster\"\n",
    "    }\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aa41923-6b59-4e62-9f21-c3ea57af68a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delhi is the capital city of India, located in the northern part of the country. It is situated on the Yamuna River in the National Capital Territory of Delhi (NCT). Delhi is a major urban center and a hub for politics, economy, culture, and tourism in India.\n"
     ]
    }
   ],
   "source": [
    "llm_obj = ChatGroq(model=\"llama-3.1-8b-instant\",api_key=os.getenv('GROQ_API_KEY'))\n",
    "r = llm_obj.invoke(\"Where is Delhi?\")\n",
    "print(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b02f3bf-113b-44c2-b9f1-b097d5077d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0584377c-f818-44ae-b1bc-0caae6978ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a4b49fd-0501-478a-85d2-4c399cdeb6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tavily-python in c:\\programdata\\anaconda3\\lib\\site-packages (0.7.21)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from tavily-python) (2.32.5)\n",
      "Requirement already satisfied: tiktoken>=0.5.1 in c:\\users\\karth\\appdata\\roaming\\python\\python313\\site-packages (from tavily-python) (0.9.0)\n",
      "Requirement already satisfied: httpx in c:\\programdata\\anaconda3\\lib\\site-packages (from tavily-python) (0.28.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\programdata\\anaconda3\\lib\\site-packages (from tiktoken>=0.5.1->tavily-python) (2024.11.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->tavily-python) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->tavily-python) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->tavily-python) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->tavily-python) (2025.6.15)\n",
      "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx->tavily-python) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx->tavily-python) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx->tavily-python) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio->httpx->tavily-python) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~angchain-community (C:\\ProgramData\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-community (C:\\ProgramData\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-community (C:\\ProgramData\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37669de7-01fa-4351-ae1e-754f181faaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Where is delhi?', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.burningcompass.com/on-world-map/where-is-delhi.html', 'title': 'Where is Delhi Located ? - Delhi on World Map - BurningCompass', 'content': 'Delhi is a major metropolitan region in northern India, located on the Indo-Gangetic plains along the western bank of the Yamuna River. Administratively, the', 'score': 0.8790744, 'raw_content': None}, {'url': 'https://www.quora.com/Where-is-Delhi-1', 'title': 'Where is Delhi? - Quora', 'content': 'Delhi is Union territory located in the Northern part of India and is surrounded by Haryana on three sides and by UP on one side. It is neither', 'score': 0.86954874, 'raw_content': None}, {'url': 'https://www.britannica.com/place/Delhi', 'title': 'Delhi | History, Population, Map, & Facts - Britannica', 'content': 'Delhi is a city and national capital territory in north-central India. It consists of two parts: Old Delhi, the historic city, and New Delhi, which became the capital of British India in the 20th century and has been the capital of India since 1947. As one of India’s largest urban areas, Delhi is a commercial, transport, and cultural hub, as well as the country’s political center. Delhi, a city and union territory, is the national capital of India, located in the north-central part of the country. It consists of two main parts: Old Delhi, the historic city in the north, and New Delhi, the capital of India since 1947, in the south. **Delhi**, city and national capital, and union territory, north-central India. The city of Delhi actually consists of two components: Old Delhi, in the north, the historic city; and New Delhi, in the south, since 1947 the capital of India, built in the first part of the 20th century as the capital of British India.', 'score': 0.85097736, 'raw_content': None}, {'url': 'https://www.latlong.net/place/delhi-india-27572.html', 'title': 'Where is Delhi, India on Map Lat Long Coordinates', 'content': \"Delhi, India is located at India country in the Cities place category with the gps coordinates of 28° 40' 44.6844'' N and 77° 4' 10.9560'' E.\", 'score': 0.7971311, 'raw_content': None}, {'url': 'https://in.pinterest.com/pin/map-of-delhi-usa-and-india--281686151677131472/', 'title': 'Where is Delhi , New York - Pinterest - India', 'content': 'Delhi City Map - Delhi, officially the National Capital Territory of Delhi that includes the Indian Capital. A complete information about Delhi City with map', 'score': 0.7152057, 'raw_content': None}], 'response_time': 1.12, 'request_id': '31ff8841-348d-4a1b-a344-29b9ffc2dc74'}\n"
     ]
    }
   ],
   "source": [
    "from tavily import TavilyClient\n",
    "\n",
    "tavily_client = TavilyClient(api_key=\"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\")\n",
    "response = tavily_client.search(\"Where is delhi?\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eb5361b-7a35-48cb-b71f-f098809f4d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain_core.messages import HumanMessage,AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ef8e13b-fd12-4c59-b2ab-b9149f25dd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's a lovely day in Bangalore today. The current weather conditions are:\n",
      "\n",
      "- Sunny: Expect plenty of sunshine today.\n",
      "- Temperature: A mild 19°C, making it a great day to be outdoors.\n",
      "- Wind: Coming from the east at 12 mph, which is relatively gentle.\n",
      "- Humidity: A comfortable 68%, neither too dry nor too humid.\n",
      "\n",
      "Overall, it's a pleasant day to explore the city, go for a walk, or simply enjoy the outdoors.\n"
     ]
    }
   ],
   "source": [
    "search_response = requests.post(\n",
    "    \"https://api.tavily.com/search\",\n",
    "    headers={\"Authorization\": f\"Bearer {os.getenv('TAVILY_API_KEY')}\"},\n",
    "    json={\n",
    "        \"query\": \"weather in Bangalore today\",  # query, \n",
    "        \"search_depth\": \"basic\", \n",
    "        \"include_answer\": True\n",
    "    }\n",
    ")\n",
    "data = search_response.json()\n",
    "web_answer = data.get(\"answer\", \"No real-time info found.\")\n",
    "\n",
    "query = \"What is the weather in Bangalore today?\"\n",
    "prompt = f\"{query}.\\n Answer based on the following information: {web_answer}\"\n",
    "\n",
    "response = llm_obj.invoke([\n",
    "    HumanMessage(content=prompt)\n",
    "])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529408aa-39d8-4e53-bef2-282b349d4a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfdc7f1c-0bac-440d-a538-0722b2e62852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='you are helpful assistant', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='i likes to read ruby books', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system','you are helpful assistant'),\n",
    "        ('human','i likes to read {mybook} books')\n",
    "    ]\n",
    ")\n",
    "prompt.format_messages(mybook=\"ruby\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6732c71e-37de-4fa0-9fb5-0f4e53d8af85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_obj.invoke(\"what is langchain?\") --->response --->-- \n",
    "# \n",
    "# llm_obj.invoke([HumanMessage(content=\"what is Langchain?\"]) ---> AIMessage(content=\"Langchain is a framework..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "845b8a3b-03d3-4fc9-a035-349a001f3b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_obj = ChatGroq(model=\"llama-3.1-8b-instant\",api_key=os.getenv('GROQ_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d92a265a-9ea5-4bf7-85da-31a1f73bae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage,AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e143b924-8ff3-4db8-a500-56a60da2214e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Langchain is an open-source platform that provides a framework for building and integrating large language models (LLMs) into various applications. It was founded in 2022 by David Moore, a well-known developer and researcher in the field of natural language processing (NLP).\\n\\nThe main goal of Langchain is to enable developers to easily integrate LLMs into their projects, allowing them to build more sophisticated and conversational AI experiences. The platform provides a set of APIs and tools that make it easier to work with LLMs, including:\\n\\n1. **LLM integration**: Langchain provides pre-built integrations with popular LLMs like LLaMA, BERT, and RoBERTa, making it easy to access their capabilities.\\n2. **Conversation flow**: Langchain allows developers to define conversation flows using a simple, intuitive language, making it easier to build complex conversational interfaces.\\n3. **Contextual understanding**: Langchain's platform is designed to handle contextual understanding, allowing LLMs to retain information and update their understanding of the conversation over time.\\n4. **Multi-model support**: Langchain supports the use of multiple LLMs in a single application, enabling developers to combine the strengths of different models to achieve better results.\\n\\nSome of the key benefits of using Langchain include:\\n\\n1. **Ease of use**: Langchain simplifies the process of integrating LLMs into applications, making it easier for developers to build conversational AI experiences.\\n2. **Flexibility**: Langchain's platform provides a high degree of flexibility, allowing developers to customize and extend its capabilities to meet their specific needs.\\n3. **Scalability**: Langchain is designed to handle large volumes of conversations and can scale to meet the needs of complex applications.\\n\\nOverall, Langchain is an exciting development in the field of conversational AI, enabling developers to build more sophisticated and engaging experiences using large language models.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 384, 'prompt_tokens': 40, 'total_tokens': 424, 'completion_time': 0.552496448, 'prompt_time': 0.002744297, 'queue_time': 0.046408793, 'total_time': 0.555240745}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c26e5-bfc1-7fd1-94cf-16e8e6cd44d5-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 40, 'output_tokens': 384, 'total_tokens': 424})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_obj.invoke([HumanMessage(content=\"What is Langchain?\")]) # same as llm_obj.invoke(\"Query?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52193c2-e322-4c7d-8d2b-29ccf1ea6279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "requests.get(URL - Get the resource) \n",
    "requests.post(Create  - Resource - object)\n",
    "requests.put(URL-Content-object-modification)\n",
    "requests.delete(URL) # delete the resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "381059d0-e600-42d4-9ce3-3748f11edb39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get('https://www.google.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ba1c3f-0b91-4ea8-8a17-035ab83d46e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client ------>-------request------->--------webserver----->---------process ..\n",
    "                   ============<===================================\n",
    "                             WebPage - <html>...{{data}}...</html>\n",
    "                             Data  - json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "839fa4bf-7be2-4cb2-a568-5ff83feffc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://www.google.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cf831e8-ec0e-49eb-937f-187eb25d6e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': 'Wed, 04 Feb 2026 04:28:40 GMT', 'Expires': '-1', 'Cache-Control': 'private, max-age=0', 'Content-Type': 'text/html; charset=ISO-8859-1', 'Content-Security-Policy-Report-Only': \"object-src 'none';base-uri 'self';script-src 'nonce-MoF6VD7FR94eZx0O74hpMA' 'strict-dynamic' 'report-sample' 'unsafe-eval' 'unsafe-inline' https: http:;report-uri https://csp.withgoogle.com/csp/gws/other-hp\", 'Reporting-Endpoints': 'default=\"//www.google.com/httpservice/retry/jserror?ei=-MqCadrQBcmQwbkPiZj-oAI&cad=crash\"', 'Accept-CH': 'Sec-CH-Prefers-Color-Scheme', 'P3P': 'CP=\"This is not a P3P policy! See g.co/p3phelp for more info.\"', 'Content-Encoding': 'gzip', 'Server': 'gws', 'X-XSS-Protection': '0', 'X-Frame-Options': 'SAMEORIGIN', 'Set-Cookie': '__Secure-STRP=AD6Dogs1w6aL3AOQ1N1IyUtt-tjtYOyfOtjKVMGPzvmOtmsvBaDPo8cW_w45c3u5rFToPafGaTo2JjtCBBKoPXhfOIWg5wPjhA; expires=Wed, 04-Feb-2026 04:33:40 GMT; path=/; domain=.google.com; Secure; SameSite=strict, AEC=AaJma5tpN6FNgZ3T1Hh7gyhfKnozGScAmwEQux2IZ6ASCshAO_-tRcGLYg; expires=Mon, 03-Aug-2026 04:28:40 GMT; path=/; domain=.google.com; Secure; HttpOnly; SameSite=lax, NID=528=Qo018XjamPupxOHQb7YhU24qw2KCdiHO73ODO2dvHjrfAxsX-WxZuL_L1whhWSISI4Lto-7ikWr3SuWvv5UWXVA5yTLL-3evEpv_4rENR0mAUM-00ocT8wjAqTUEZpKvqETGEFszPxWL7vI59_HNfoU0R1E-5wRdhxdHYLVGm9Rw0FXV11GvB6ithRUd394kDiG7_DABsl3w_yeyHSSghyaQzrl9xGGgLBM; expires=Thu, 06-Aug-2026 04:28:40 GMT; path=/; domain=.google.com; HttpOnly, __Secure-BUCKET=CI4F; expires=Mon, 03-Aug-2026 04:28:40 GMT; path=/; domain=.google.com; Secure; HttpOnly', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000', 'Transfer-Encoding': 'chunked'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae9418e0-cc98-4866-91a4-e8f5a515924d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text/html; charset=ISO-8859-1'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.headers['Content-Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bc8c744-8b48-43d1-b957-b7fcd2425dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 19774\n"
     ]
    }
   ],
   "source": [
    "web_page = r.text\n",
    "print(type(web_page),len(web_page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1a89318-7a71-4155-8dbd-90deb7c0c5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': 'Wed, 04 Feb 2026 04:39:59 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Cache-Control': 'public, max-age=60, s-maxage=60', 'Vary': 'Accept,Accept-Encoding, Accept, X-Requested-With', 'ETag': 'W/\"61f25e2a55611f7eaf75a20ed5fe501245c5af99bc383854f5442975318fad26\"', 'X-GitHub-Media-Type': 'github.v3; format=json', 'x-github-api-version-selected': '2022-11-28', 'Access-Control-Expose-Headers': 'ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Resource, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, X-GitHub-SSO, X-GitHub-Request-Id, Deprecation, Sunset', 'Access-Control-Allow-Origin': '*', 'Strict-Transport-Security': 'max-age=31536000; includeSubdomains; preload', 'X-Frame-Options': 'deny', 'X-Content-Type-Options': 'nosniff', 'X-XSS-Protection': '0', 'Referrer-Policy': 'origin-when-cross-origin, strict-origin-when-cross-origin', 'Content-Security-Policy': \"default-src 'none'\", 'Content-Encoding': 'gzip', 'Server': 'github.com', 'Accept-Ranges': 'bytes', 'X-RateLimit-Limit': '60', 'X-RateLimit-Remaining': '58', 'X-RateLimit-Reset': '1770183554', 'X-RateLimit-Resource': 'core', 'X-RateLimit-Used': '2', 'Content-Length': '1008', 'X-GitHub-Request-Id': '4430:A1BE2:256CAE:334F4F:6982CD9F'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get(\"https://api.github.com/users/hadley/orgs\")\n",
    "r.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbb852c9-80c1-4ad3-a553-b275fbee94b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'application/json; charset=utf-8'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.headers['Content-Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbc029ae-f093-4300-acdf-aff0a87763f9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'login': 'ggobi',\n",
       "  'id': 423638,\n",
       "  'node_id': 'MDEyOk9yZ2FuaXphdGlvbjQyMzYzOA==',\n",
       "  'url': 'https://api.github.com/orgs/ggobi',\n",
       "  'repos_url': 'https://api.github.com/orgs/ggobi/repos',\n",
       "  'events_url': 'https://api.github.com/orgs/ggobi/events',\n",
       "  'hooks_url': 'https://api.github.com/orgs/ggobi/hooks',\n",
       "  'issues_url': 'https://api.github.com/orgs/ggobi/issues',\n",
       "  'members_url': 'https://api.github.com/orgs/ggobi/members{/member}',\n",
       "  'public_members_url': 'https://api.github.com/orgs/ggobi/public_members{/member}',\n",
       "  'avatar_url': 'https://avatars.githubusercontent.com/u/423638?v=4',\n",
       "  'description': ''},\n",
       " {'login': 'rstudio',\n",
       "  'id': 513560,\n",
       "  'node_id': 'MDEyOk9yZ2FuaXphdGlvbjUxMzU2MA==',\n",
       "  'url': 'https://api.github.com/orgs/rstudio',\n",
       "  'repos_url': 'https://api.github.com/orgs/rstudio/repos',\n",
       "  'events_url': 'https://api.github.com/orgs/rstudio/events',\n",
       "  'hooks_url': 'https://api.github.com/orgs/rstudio/hooks',\n",
       "  'issues_url': 'https://api.github.com/orgs/rstudio/issues',\n",
       "  'members_url': 'https://api.github.com/orgs/rstudio/members{/member}',\n",
       "  'public_members_url': 'https://api.github.com/orgs/rstudio/public_members{/member}',\n",
       "  'avatar_url': 'https://avatars.githubusercontent.com/u/513560?v=4',\n",
       "  'description': ''},\n",
       " {'login': 'rstats',\n",
       "  'id': 722735,\n",
       "  'node_id': 'MDEyOk9yZ2FuaXphdGlvbjcyMjczNQ==',\n",
       "  'url': 'https://api.github.com/orgs/rstats',\n",
       "  'repos_url': 'https://api.github.com/orgs/rstats/repos',\n",
       "  'events_url': 'https://api.github.com/orgs/rstats/events',\n",
       "  'hooks_url': 'https://api.github.com/orgs/rstats/hooks',\n",
       "  'issues_url': 'https://api.github.com/orgs/rstats/issues',\n",
       "  'members_url': 'https://api.github.com/orgs/rstats/members{/member}',\n",
       "  'public_members_url': 'https://api.github.com/orgs/rstats/public_members{/member}',\n",
       "  'avatar_url': 'https://avatars.githubusercontent.com/u/722735?v=4',\n",
       "  'description': None},\n",
       " {'login': 'ropensci',\n",
       "  'id': 1200269,\n",
       "  'node_id': 'MDEyOk9yZ2FuaXphdGlvbjEyMDAyNjk=',\n",
       "  'url': 'https://api.github.com/orgs/ropensci',\n",
       "  'repos_url': 'https://api.github.com/orgs/ropensci/repos',\n",
       "  'events_url': 'https://api.github.com/orgs/ropensci/events',\n",
       "  'hooks_url': 'https://api.github.com/orgs/ropensci/hooks',\n",
       "  'issues_url': 'https://api.github.com/orgs/ropensci/issues',\n",
       "  'members_url': 'https://api.github.com/orgs/ropensci/members{/member}',\n",
       "  'public_members_url': 'https://api.github.com/orgs/ropensci/public_members{/member}',\n",
       "  'avatar_url': 'https://avatars.githubusercontent.com/u/1200269?v=4',\n",
       "  'description': 'Tools and R Packages for Open Science'},\n",
       " {'login': 'rjournal',\n",
       "  'id': 3330561,\n",
       "  'node_id': 'MDEyOk9yZ2FuaXphdGlvbjMzMzA1NjE=',\n",
       "  'url': 'https://api.github.com/orgs/rjournal',\n",
       "  'repos_url': 'https://api.github.com/orgs/rjournal/repos',\n",
       "  'events_url': 'https://api.github.com/orgs/rjournal/events',\n",
       "  'hooks_url': 'https://api.github.com/orgs/rjournal/hooks',\n",
       "  'issues_url': 'https://api.github.com/orgs/rjournal/issues',\n",
       "  'members_url': 'https://api.github.com/orgs/rjournal/members{/member}',\n",
       "  'public_members_url': 'https://api.github.com/orgs/rjournal/public_members{/member}',\n",
       "  'avatar_url': 'https://avatars.githubusercontent.com/u/3330561?v=4',\n",
       "  'description': None},\n",
       " {'login': 'r-dbi',\n",
       "  'id': 5695665,\n",
       "  'node_id': 'MDEyOk9yZ2FuaXphdGlvbjU2OTU2NjU=',\n",
       "  'url': 'https://api.github.com/orgs/r-dbi',\n",
       "  'repos_url': 'https://api.github.com/orgs/r-dbi/repos',\n",
       "  'events_url': 'https://api.github.com/orgs/r-dbi/events',\n",
       "  'hooks_url': 'https://api.github.com/orgs/r-dbi/hooks',\n",
       "  'issues_url': 'https://api.github.com/orgs/r-dbi/issues',\n",
       "  'members_url': 'https://api.github.com/orgs/r-dbi/members{/member}',\n",
       "  'public_members_url': 'https://api.github.com/orgs/r-dbi/public_members{/member}',\n",
       "  'avatar_url': 'https://avatars.githubusercontent.com/u/5695665?v=4',\n",
       "  'description': 'R + databases'},\n",
       " {'login': 'RConsortium',\n",
       "  'id': 15366137,\n",
       "  'node_id': 'MDEyOk9yZ2FuaXphdGlvbjE1MzY2MTM3',\n",
       "  'url': 'https://api.github.com/orgs/RConsortium',\n",
       "  'repos_url': 'https://api.github.com/orgs/RConsortium/repos',\n",
       "  'events_url': 'https://api.github.com/orgs/RConsortium/events',\n",
       "  'hooks_url': 'https://api.github.com/orgs/RConsortium/hooks',\n",
       "  'issues_url': 'https://api.github.com/orgs/RConsortium/issues',\n",
       "  'members_url': 'https://api.github.com/orgs/RConsortium/members{/member}',\n",
       "  'public_members_url': 'https://api.github.com/orgs/RConsortium/public_members{/member}',\n",
       "  'avatar_url': 'https://avatars.githubusercontent.com/u/15366137?v=4',\n",
       "  'description': 'The R Consortium, Inc was established to provide support to the R Foundation and R Community, using maintaining and distributing R software.'},\n",
       " {'login': 'tidyverse',\n",
       "  'id': 22032646,\n",
       "  'node_id': 'MDEyOk9yZ2FuaXphdGlvbjIyMDMyNjQ2',\n",
       "  'url': 'https://api.github.com/orgs/tidyverse',\n",
       "  'repos_url': 'https://api.github.com/orgs/tidyverse/repos',\n",
       "  'events_url': 'https://api.github.com/orgs/tidyverse/events',\n",
       "  'hooks_url': 'https://api.github.com/orgs/tidyverse/hooks',\n",
       "  'issues_url': 'https://api.github.com/orgs/tidyverse/issues',\n",
       "  'members_url': 'https://api.github.com/orgs/tidyverse/members{/member}',\n",
       "  'public_members_url': 'https://api.github.com/orgs/tidyverse/public_members{/member}',\n",
       "  'avatar_url': 'https://avatars.githubusercontent.com/u/22032646?v=4',\n",
       "  'description': 'The tidyverse is a collection of R packages that share common principles and are designed to work together seamlessly'},\n",
       " {'login': 'r-lib',\n",
       "  'id': 22618716,\n",
       "  'node_id': 'MDEyOk9yZ2FuaXphdGlvbjIyNjE4NzE2',\n",
       "  'url': 'https://api.github.com/orgs/r-lib',\n",
       "  'repos_url': 'https://api.github.com/orgs/r-lib/repos',\n",
       "  'events_url': 'https://api.github.com/orgs/r-lib/events',\n",
       "  'hooks_url': 'https://api.github.com/orgs/r-lib/hooks',\n",
       "  'issues_url': 'https://api.github.com/orgs/r-lib/issues',\n",
       "  'members_url': 'https://api.github.com/orgs/r-lib/members{/member}',\n",
       "  'public_members_url': 'https://api.github.com/orgs/r-lib/public_members{/member}',\n",
       "  'avatar_url': 'https://avatars.githubusercontent.com/u/22618716?v=4',\n",
       "  'description': ''},\n",
       " {'login': 'rstudio-education',\n",
       "  'id': 34165516,\n",
       "  'node_id': 'MDEyOk9yZ2FuaXphdGlvbjM0MTY1NTE2',\n",
       "  'url': 'https://api.github.com/orgs/rstudio-education',\n",
       "  'repos_url': 'https://api.github.com/orgs/rstudio-education/repos',\n",
       "  'events_url': 'https://api.github.com/orgs/rstudio-education/events',\n",
       "  'hooks_url': 'https://api.github.com/orgs/rstudio-education/hooks',\n",
       "  'issues_url': 'https://api.github.com/orgs/rstudio-education/issues',\n",
       "  'members_url': 'https://api.github.com/orgs/rstudio-education/members{/member}',\n",
       "  'public_members_url': 'https://api.github.com/orgs/rstudio-education/public_members{/member}',\n",
       "  'avatar_url': 'https://avatars.githubusercontent.com/u/34165516?v=4',\n",
       "  'description': ''}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec0fe11-1760-411a-ab22-a5ee8a312ff0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be283caa-a2de-47f0-93b4-9b1ae8b1fd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage,AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52d1013a-414e-4050-998f-577c4ea8d68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Karthik, nice to meet you. You're an instructor, that's great. What subject or field do you teach? Are you looking for any assistance or would you like to discuss something specific?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 45, 'total_tokens': 88, 'completion_time': 0.064715209, 'prompt_time': 0.002130878, 'queue_time': 0.045219822, 'total_time': 0.066846087}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c26fb-fb6d-7652-a0a4-c736cf48fb5c-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 45, 'output_tokens': 43, 'total_tokens': 88})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_obj.invoke([HumanMessage(content=\"Hello my name is Karthik I am instructor\")]) # same as llm_obj.invoke(\"Query?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c73b75d-b222-4da8-89e9-a355b8941a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't have any information about your name. I'm a large language model, I don't have the ability to store or retain personal information about individual users, including their names. Each time you interact with me, it's a new conversation. If you'd like to share your name with me, I'd be happy to chat with you and address you by name!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 41, 'total_tokens': 117, 'completion_time': 0.102652348, 'prompt_time': 0.001926423, 'queue_time': 0.045630333, 'total_time': 0.104578771}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c26fc-631a-7643-9bf5-cff805e9dca0-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 41, 'output_tokens': 76, 'total_tokens': 117})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_obj.invoke([HumanMessage(content=\"Hi Tell me my name?\")]) # same as llm_obj.invoke(\"Query?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cdb7b0-58a1-44e7-940a-8f323642d16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "+-------------------------------\n",
    "| UserQ:  What is python?\n",
    "| AI:  ....\n",
    "| UserQ: list out any 5 important features?\n",
    "| AI: .. there are 5 important python features..\n",
    "|        .... ....\n",
    "|\n",
    "+----------------------------------\n",
    "\n",
    "+--------------------------\n",
    "| User: Hello my name is Tom renewal my website domain...\n",
    "| AI: Hello Tom....mynmae is userA ...\n",
    "| User: renewal my website ...\n",
    "| AI : Enter your website domain name?\n",
    "| User: \n",
    "---------------------------------------//session expired \n",
    "|\n",
    "| User: I will type website name ->www.abc.com\n",
    "| AI : I userB from ISP provider ...\n",
    "\n",
    "\n",
    " +------------------------------------------------------------+\n",
    " | sessionID               |  Chat(Human+AI)                  |\n",
    " |-------------------------|----------------------------------|\n",
    " | session1                | User: ...\n",
    " |                         | AI_response:\n",
    " |                         | User:\n",
    " |                         | AI_reponse\n",
    " --------------------------------------------------------------\n",
    " | session2                | User: ...\n",
    " |                         |\n",
    " |                         |\n",
    " ---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3476d10b-812f-474e-a670-4c0de9c4548a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p101': 'pA', 'p102': 'pB', 'p103': 'pC'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores = {}\n",
    "stores['p101'] = 'pA'\n",
    "stores['p102'] = 'pB'\n",
    "stores['p103'] = 'pC'\n",
    "stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11cbaefa-bed5-492d-b82a-cb44849a872f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p101': ['pA', 1000, 'pVendor1'],\n",
       " 'p102': ['pB', 2000, 'pVendor2'],\n",
       " 'p103': ['pC', 3000, 'pVendor3']}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores={}\n",
    "stores['p101'] = ['pA',1000,'pVendor1']\n",
    "stores['p102'] = ['pB',2000,'pVendor2']\n",
    "stores['p103'] = ['pC',3000,'pVendor3']\n",
    "stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e28df1-3092-4501-8fb6-f11bc93c0243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74172114-9722-4e89-a1cf-34def96a13b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3021ed0-dc0a-4658-aa57-37c1e03be045",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = {}\n",
    "\n",
    "def f1(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in chat_history:\n",
    "        chat_history[session_id] = ChatMessageHistory()\n",
    "    return chat_history[session_id]\n",
    "\n",
    "obj = RunnableWithMessageHistory(llm_obj,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "376efac8-6add-4dd6-8faf-4f6f80520328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Karthik. As an instructor, I'm here to help you with any questions or topics you'd like to discuss. What subject or area would you like to focus on today?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 45, 'total_tokens': 88, 'completion_time': 0.074003574, 'prompt_time': 0.002687624, 'queue_time': 0.046701036, 'total_time': 0.076691198}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c2711-4070-75c3-999d-258503978d6f-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 45, 'output_tokens': 43, 'total_tokens': 88})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_config={\"configurable\":{\"session_id\":\"chat-1\"}}\n",
    "obj.invoke([HumanMessage(content=\"Hello my name is Karthik I am instructor\")],config=my_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fd7cdcf-d9e0-4837-b448-6d2def2c1d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Karthik.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 103, 'total_tokens': 111, 'completion_time': 0.005253969, 'prompt_time': 0.006212986, 'queue_time': 0.046431571, 'total_time': 0.011466955}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c2711-be5e-7493-9b97-1e4362d37ff9-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 103, 'output_tokens': 8, 'total_tokens': 111})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.invoke([HumanMessage(content=\"Hi Tell me my name?\")],config=my_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1329c5-5fd5-415c-bf7f-8ff77310ece2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "system prompt - 500\n",
    "rule          - 1000\n",
    "chathistory   - 10,000\n",
    "FAISS         - 2000\n",
    "tool output   - 3000\n",
    "userQuery     - 100\n",
    "model answer ->  2000 <===\n",
    "----------------------------\n",
    "                  18600\n",
    "\n",
    "user query token limit \n",
    "model response token limit \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2477c24-d439-4df8-bcbc-66ae0bf43e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't have information about your name, as our conversation just started. I'm a large language model, I don't have personal interactions or retain knowledge about individual users. If you'd like to share your name, I can use it to personalize our conversation.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 41, 'total_tokens': 95, 'completion_time': 0.088773353, 'prompt_time': 0.002885346, 'queue_time': 0.04712566, 'total_time': 0.091658699}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c2721-6c8c-7a72-972f-4e6b38369f3b-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 41, 'output_tokens': 54, 'total_tokens': 95})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_config={\"configurable\":{\"session_id\":\"chat-2\"}}\n",
    "obj.invoke([HumanMessage(content=\"Hi Tell me my name?\")],config=my_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26abaf48-7084-40f4-a523-f5f8e630a279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat-1': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hello my name is Karthik I am instructor', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Nice to meet you, Karthik. As an instructor, I'm here to help you with any questions or topics you'd like to discuss. What subject or area would you like to focus on today?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 45, 'total_tokens': 88, 'completion_time': 0.074003574, 'prompt_time': 0.002687624, 'queue_time': 0.046701036, 'total_time': 0.076691198}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c2711-4070-75c3-999d-258503978d6f-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 45, 'output_tokens': 43, 'total_tokens': 88}), HumanMessage(content='Hi Tell me my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Karthik.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 103, 'total_tokens': 111, 'completion_time': 0.005253969, 'prompt_time': 0.006212986, 'queue_time': 0.046431571, 'total_time': 0.011466955}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c2711-be5e-7493-9b97-1e4362d37ff9-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 103, 'output_tokens': 8, 'total_tokens': 111})]),\n",
       " 'chat-2': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi Tell me my name?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I don't have information about your name, as our conversation just started. I'm a large language model, I don't have personal interactions or retain knowledge about individual users. If you'd like to share your name, I can use it to personalize our conversation.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 41, 'total_tokens': 95, 'completion_time': 0.088773353, 'prompt_time': 0.002885346, 'queue_time': 0.04712566, 'total_time': 0.091658699}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c2721-6c8c-7a72-972f-4e6b38369f3b-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 41, 'output_tokens': 54, 'total_tokens': 95})])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "783c746c-2041-4a88-a02f-8b0212a8ac89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
       "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]), kwargs={}, config={}, config_factories=[], get_session_history=<function f1 at 0x000001E16F43AA20>, history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02d43010-5721-47b7-a7f5-92305b48568e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangChain is an open-source Python library that allows developers to build, train, and deploy large language models and AI applications.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 130, 'total_tokens': 156, 'completion_time': 0.064307884, 'prompt_time': 0.008112408, 'queue_time': 0.045344339, 'total_time': 0.072420292}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c2723-96e7-7030-b74d-55962c70a154-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 130, 'output_tokens': 26, 'total_tokens': 156})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_config={\"configurable\":{\"session_id\":\"chat-1\"}}\n",
    "obj.invoke([HumanMessage(content=\"Explain what is langchain in one line?\")],config=my_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6bf9f78-ebea-48df-a691-8f664db98d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='Hello my name is Karthik I am instructor', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Nice to meet you, Karthik. As an instructor, I'm here to help you with any questions or topics you'd like to discuss. What subject or area would you like to focus on today?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 45, 'total_tokens': 88, 'completion_time': 0.074003574, 'prompt_time': 0.002687624, 'queue_time': 0.046701036, 'total_time': 0.076691198}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c2711-4070-75c3-999d-258503978d6f-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 45, 'output_tokens': 43, 'total_tokens': 88}), HumanMessage(content='Hi Tell me my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Karthik.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 103, 'total_tokens': 111, 'completion_time': 0.005253969, 'prompt_time': 0.006212986, 'queue_time': 0.046431571, 'total_time': 0.011466955}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c2711-be5e-7493-9b97-1e4362d37ff9-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 103, 'output_tokens': 8, 'total_tokens': 111}), HumanMessage(content='Explain what is langchain in one line?', additional_kwargs={}, response_metadata={}), AIMessage(content='LangChain is an open-source Python library that allows developers to build, train, and deploy large language models and AI applications.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 130, 'total_tokens': 156, 'completion_time': 0.064307884, 'prompt_time': 0.008112408, 'queue_time': 0.045344339, 'total_time': 0.072420292}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c2723-96e7-7030-b74d-55962c70a154-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 130, 'output_tokens': 26, 'total_tokens': 156})])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history['chat-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d30cb9-42bf-4332-8130-16fc027a3e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-1 Load pdf file\n",
    "\n",
    "# Step-2 Split the docs - chunks - RecursiveCharacterTextSplitter\n",
    "\n",
    "# Step-3 embedding object\n",
    "\n",
    "# Step-4  VectorDB\n",
    "\n",
    "# Step-5 Retrieval object\n",
    "\n",
    "# Step-6 LLM object\n",
    "\n",
    "## Step-7 Prompt with History\n",
    "ChatPromptTemplate.form_template(\"\"\"\n",
    "user following context and chat history to answer the question\n",
    "chat history:\n",
    "{history}\n",
    "Context:\n",
    "{context}\n",
    "Question:\n",
    "{query}\n",
    "\"\"\")\n",
    "# Step 8: QAChain RetrievalQA\n",
    "\n",
    "# Step 9: Chat history\n",
    "chat_history = {}\n",
    "\n",
    "def f1(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in chat_history:\n",
    "        chat_history[session_id] = ChatMessageHistory()\n",
    "    return chat_history[session_id]\n",
    "\n",
    "obj = RunnableWithMessageHistory(llm_obj,f1,input_messages_key=\"query\",history_messages_key=\"history\")\n",
    "\n",
    "# Step 10: Create session ID \n",
    "session_id=\"session-1\"\n",
    "query1=\"....\"\n",
    "\n",
    "# Step 11: user query\n",
    "obj.invoke({\"query\":..},config={\"configurable\":{\"session\":session_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "771e37a5-eca3-45e0-9d9b-09a22067ef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dynamically insert a message - at runtime\n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "#help(ChatPromptTemplate)\n",
    "\n",
    "ChatPromptTemplate.from_messages([\n",
    "(\"system\",\"You are helpful assistant\"), <== fixed \n",
    "MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                                     |<-- dynamically list of messages \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "605de89e-9573-4b94-8f64-994794768bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24127c7b-a2cb-4a59-a743-0a72627dcfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are helpful assistant. Answer all the question in {language}.\"),\n",
    "    MessagesPlaceholder(variable_name=\"question\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf9f4cc5-1c23-42da-81b0-b3772b5cf002",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt|llm_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d8f3b58e-42bf-4526-8961-8d6e301b17ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Bonjour Tom, enchanté ! Comment puis-je vous aider aujourd'hui ?\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 52, 'total_tokens': 69, 'completion_time': 0.025218989, 'prompt_time': 0.002478203, 'queue_time': 0.045736143, 'total_time': 0.027697192}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019c2732-645c-7100-976d-cc2b29427d34-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 52, 'output_tokens': 17, 'total_tokens': 69}\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({'question':[HumanMessage(content=\"Hello my name is Tom\")],\"language\":\"french\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "013129cc-3d76-430a-bfe7-897508805919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour Tom, enchanté ! Comment puis-je vous aider aujourd'hui ?\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e0669b7-eb4f-4d21-879a-2594e68f250c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "नमस्ते टॉम, मैं आपकी सहायता के लिए यहाँ हूँ। क्या मैं आपकी किसी समस्या या प्रश्न का समाधान कर सकता हूँ?\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({'question':[HumanMessage(content=\"Hello my name is Tom\")],\"language\":\"hindi\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "163c4304-8eb1-48b6-a3fe-6735ec85db87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "నమస్కారం టాం. నేను సహాయకుడిని అనుకుంటున్నాను. ఏ ప్రశ్నలకు సహాయం చేయాలని అడగండి.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({'question':[HumanMessage(content=\"Hello my name is Tom\")],\"language\":\"telugu\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d6d2dbd-ea3d-48de-bcfb-923428097e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "வணக்கம்! நான் உங்களுக்கு உதவுவதில் நல்ல ஆசை. நீங்கள் தமிழ்நாட்டில் இருந்து அல்லவா என்று அறிந்து கொள்ள வேண்டுமா? உங்கள் பெயர் 'டாம்' என்று சொல்லுகிறீர்கள்.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({'question':[HumanMessage(content=\"Hello my name is Tom\")],\"language\":\"tamil\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "50981702-4c73-4c47-9a2c-1841773b97d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ನಮಸ್ಕಾರ Tom, ನೀವು ಯಾವ ಭಾಷೆಯಲ್ಲಿ ಗುರುತಿಸಿಕೊಳ್ಳಬೇಕು ಎಂಬುದರ ಬಗ್ಗೆ ನಿಮಗೆ ಹೇಳಲು ಬೇಕು?\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({'question':[HumanMessage(content=\"Hello my name is Tom\")],\"language\":\"kannada\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c72294-f082-435b-8bd4-0f628cd04c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
